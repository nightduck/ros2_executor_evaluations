{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "ROS_DISTRO = 'rolling'\n",
    "sys.path.insert(0, f'/opt/ros/{ROS_DISTRO}/lib/python3.121/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tracetools_analysis.loading import load_file\n",
    "from tracetools_analysis.processor import Processor\n",
    "from tracetools_analysis.processor.cpu_time import CpuTimeHandler\n",
    "from tracetools_analysis.processor.ros2 import Ros2Handler\n",
    "from tracetools_analysis.utils.cpu_time import CpuTimeDataModelUtil\n",
    "from tracetools_analysis.utils.ros2 import Ros2DataModelUtil\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def load_dropped_jobs(filename):\n",
    "  with open(filename, 'r') as f:\n",
    "    dropped_jobs = {}\n",
    "    process_line = False\n",
    "    for line in f:\n",
    "      if line.startswith(\"Dropped jobs:\"):\n",
    "        process_line = True\n",
    "        continue\n",
    "      if process_line:\n",
    "        name, stats = line.strip().split(\":\")\n",
    "        dropped, overrun, total = [int(x) for x in stats.split(\"/\")]\n",
    "        dropped_jobs[name.strip()] = float(dropped) / float(total) if total > 0 else 0\n",
    "    return dropped_jobs\n",
    "def load_inputs(string):\n",
    "  return (load_file(directory_prefix + string), load_dropped_jobs(directory_prefix + string + '.log'))\n",
    "\n",
    "def get_node_name(owner_info):\n",
    "  node_name = owner_info.split(\",\")[0].split(\":\")[1].strip()\n",
    "  return node_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load trace directory or converted trace file\n",
    "directory_prefix = \"data/timers_only_05_23/\"\n",
    "events_dict = {}\n",
    "\n",
    "def load_inputs(string):\n",
    "  return (load_file(directory_prefix + string), load_dropped_jobs(directory_prefix + string + '.log'))\n",
    "\n",
    "trace_names = ['trace-timers-only.rm.ro.60', 'trace-timers-only.rm.re.60',\n",
    "               'trace-timers-only.edf.ro.60', 'trace-timers-only.edf.re.60',\n",
    "              #  'trace-timers-only.fifo.ro.60', 'trace-timers-only.fifo.re.60',\n",
    "               'trace-timers-only.events.ro.60', 'trace-timers-only.events.re.60',\n",
    "               'trace-timers-only.static.60', 'trace-timers-only.default.60',\n",
    "               'trace-timers-only.rm.ro.80', 'trace-timers-only.rm.re.80',\n",
    "               'trace-timers-only.edf.ro.80', 'trace-timers-only.edf.re.80',\n",
    "              #  'trace-timers-only.fifo.ro.80', 'trace-timers-only.fifo.re.80',\n",
    "               'trace-timers-only.events.ro.80', 'trace-timers-only.events.re.80',\n",
    "               'trace-timers-only.static.80', 'trace-timers-only.default.80',\n",
    "               'trace-timers-only.rm.ro.90', 'trace-timers-only.rm.re.90',\n",
    "               'trace-timers-only.edf.ro.90', 'trace-timers-only.edf.re.90',\n",
    "              #  'trace-timers-only.fifo.ro.90', 'trace-timers-only.fifo.re.90',\n",
    "               'trace-timers-only.events.ro.90', 'trace-timers-only.events.re.90',\n",
    "               'trace-timers-only.static.90', 'trace-timers-only.default.90']\n",
    "display_names = ['RM (RO),60%', 'RM (RE),60%', 'EDF (RO),60%', 'EDF (RE),60%', 'Events (RO),60%', 'Events (RE),60%', 'Static,60%', 'Default,60%',\n",
    "                 'RM (RO),80%', 'RM (RE),80%', 'EDF (RO),80%', 'EDF (RE),80%', 'Events (RO),80%', 'Events (RE),80%', 'Static,80%', 'Default,80%',\n",
    "                 'RM (RO),90%', 'RM (RE),90%', 'EDF (RO),90%', 'EDF (RE),90%', 'Events (RO),90%', 'Events (RE),90%', 'Static,90%', 'Default,90%']\n",
    "\n",
    "# trace_names = ['sequences.rm.ro.uu', 'sequences.rm.re.uu',\n",
    "#                'sequences.events.ro.uu', 'sequences.events.re.uu',\n",
    "#                'sequences.default.uu',\n",
    "#                'sequences.rm.ro.hu', 'sequences.rm.re.hu',\n",
    "#                'sequences.events.ro.hu', 'sequences.events.re.hu',\n",
    "#                'sequences.default.hu']\n",
    "# display_names = ['RM (RO),60%', 'RM (RE),60%', 'Events (RO),60%', 'Events (RE),60%', 'Default,60%',\n",
    "#                  'RM (RO),100%', 'RM (RE),100%', 'Events (RO),100%', 'Events (RE),100%', 'Default,100%']\n",
    "# events_dict = {}\n",
    "# for trace, display in zip(trace_names, display_names):\n",
    "#   events_dict[display] = load_inputs(trace)\n",
    "\n",
    "# events_dict[\"RM, (RO)\"] =     (load_file(directory_prefix + 'timers-only-rm-ro'),     load_dropped_jobs(directory_prefix + 'timers-only-rm-ro.log'))\n",
    "# events_dict[\"RM, (RE)\"] =     (load_file(directory_prefix + 'timers-only-rm-re'),     load_dropped_jobs(directory_prefix + 'timers-only-rm-re.log'))\n",
    "# events_dict[\"EDF, (RO)\"] =    (load_file(directory_prefix + 'timers-only-edf-ro'),    load_dropped_jobs(directory_prefix + 'timers-only-edf-ro.log'))\n",
    "# events_dict[\"EDF, (RE)\"] =    (load_file(directory_prefix + 'timers-only-edf-re'),    load_dropped_jobs(directory_prefix + 'timers-only-edf-re.log'))\n",
    "# events_dict[\"Events, (RO)\"] = (load_file(directory_prefix + 'timers-only-events-ro'), load_dropped_jobs(directory_prefix + 'timers-only-events-ro.log'))\n",
    "# events_dict[\"Events, (RE)\"] = (load_file(directory_prefix + 'timers-only-events-re'), load_dropped_jobs(directory_prefix + 'timers-only-events-re.log'))\n",
    "# events_dict[\"Default\"] =      (load_file(directory_prefix + 'timers-only-default'),   load_dropped_jobs(directory_prefix + 'timers-only-default.log'))\n",
    "\n",
    "dropped_df = pd.DataFrame({\"Executor\": [], \"Utilization\": [], \"Node\": [], \"Drop Rate\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_df = None\n",
    "input_data = None\n",
    "wcet_dict = {}\n",
    "\n",
    "for trace, display in zip(trace_names, display_names):\n",
    "  events = load_inputs(trace)\n",
    "  utilization = display.split(\",\")[1]\n",
    "  name = display.split(\",\")[0]\n",
    "  dropped_jobs = events[1]\n",
    "  for node, drop_rate in dropped_jobs.items():\n",
    "    # temp_df = pd.DataFrame([[name, utilization, node, drop_rate]])\n",
    "    dropped_df = pd.concat([pd.DataFrame([[name, utilization, node, drop_rate]], columns=dropped_df.columns), dropped_df], ignore_index=True)\n",
    "\n",
    "  # # Timer manager processing\n",
    "  # tid = 2750\n",
    "  # trace_events = pd.DataFrame.from_dict(events[0])[['_name', 'timestamp', 'next_tid', 'prev_tid']]\n",
    "  # sched_events = trace_events[(trace_events['next_tid']==tid) | (trace_events['prev_tid']==tid)]\n",
    "\n",
    "  # Process\n",
    "  if len(events[0]) == 0:\n",
    "    print(\"No events found for \" + name)\n",
    "    continue\n",
    "  handler = Ros2Handler.process(events[0])\n",
    "\n",
    "  # Use data model utils to extract information\n",
    "  data_util = Ros2DataModelUtil(handler.data)\n",
    "  callback_symbols = data_util.get_callback_symbols()\n",
    "\n",
    "  if utilization != \"90%\":\n",
    "    continue\n",
    "  \n",
    "  # callback_symbols = ros2_util.get_callback_symbols()\n",
    "  for callback_object in callback_symbols.keys():\n",
    "    owner_info = data_util.get_callback_owner_info(callback_object)\n",
    "    if \"parameter_events\" in owner_info:\n",
    "      continue\n",
    "    owner_name = get_node_name(owner_info)\n",
    "    temp_df = data_util.get_callback_durations(callback_object)\n",
    "    temp_df[\"Executor\"] = name\n",
    "    temp_df[\"Node\"] = owner_name\n",
    "    if callback_df is None:\n",
    "      callback_df = temp_df\n",
    "    else:\n",
    "      callback_df = pd.concat([callback_df, temp_df], ignore_index=True)\n",
    "\n",
    "    callback_durations = data_util.get_callback_durations(callback_object)[[\"duration\"]].to_numpy(dtype=np.float64)[:-1] / 1000000.0\n",
    "    \n",
    "    if (owner_name + name) not in wcet_dict:\n",
    "      wcet_dict[owner_name + name] = callback_durations.flatten()\n",
    "    else:\n",
    "      wcet_dict[owner_name + name] = np.concatenate((wcet_dict[owner_name + name], callback_durations.flatten())).flatten()\n",
    "\n",
    "    # print(time_per_thread)\n",
    "    # print(owner_info)\n",
    "    # print(callback_durations)\n",
    "\n",
    "total_drops_df = dropped_df[dropped_df[\"Node\"] == \"Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "ax = sns.barplot(total_drops_df, y=\"Drop Rate\", x=\"Executor\", hue=\"Utilization\", palette=[\"#003f5c\", \"#7393B3\", \"#7a7a7a\"])\n",
    "ax.set_title(\"Timers Only, Uniprocessor\")\n",
    "ax.set_ylabel(\"Drop Rate\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "\n",
    "# ax.set_ylim([0, 1])\n",
    "plt.savefig(\"dropped_jobs_timers_only.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "wcet_grouped_dict = {\"Camera\": np.array([]), \"Lidar\": np.array([]), \"IMU\": np.array([])}\n",
    "for k in wcet_dict.keys():\n",
    "  # wcet_dict[k] = wcet_dict[k][wcet_dict[k] < 0.1]\n",
    "  if \"camera\" in k.lower():\n",
    "    wcet_grouped_dict[\"Camera\"] = np.concatenate((wcet_grouped_dict[\"Camera\"], wcet_dict[k]))\n",
    "  elif \"lidar\" in k.lower():\n",
    "    wcet_grouped_dict[\"Lidar\"] = np.concatenate((wcet_grouped_dict[\"Lidar\"], wcet_dict[k]))\n",
    "  elif \"imu\" in k.lower():\n",
    "    wcet_grouped_dict[\"IMU\"] = np.concatenate((wcet_grouped_dict[\"IMU\"], wcet_dict[k]))\n",
    "sns.violinplot(wcet_grouped_dict)\n",
    "plt.title(\"Timers Only, Uniprocessor\")\n",
    "plt.ylabel(\"WCET (ms)\")\n",
    "plt.show()\n",
    "wcet_grouped_dict[\"IMU\"].sort()\n",
    "print(wcet_grouped_dict[\"IMU\"][-10:])\n",
    "\n",
    "plt.figure(figsize=(30,4))\n",
    "ax = sns.violinplot(wcet_dict)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "plt.title(\"Timers Only, Uniprocessor\")\n",
    "plt.ylabel(\"WCET (ms)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# TODO: Pie chart of which types of jobs are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/workspaces/rtss2024_paper/data/benchmark_autoware_reference_system/latest/600s/rmw_cyclonedds_cpp/\"\n",
    "executors = [\"autoware_default_events\", \"autoware_default_rm\", \"autoware_default_singlethreaded\", \"autoware_default_staticsinglethreaded\"]\n",
    "duration = 600\n",
    "dirs = [directory + e for e in executors]\n",
    "\n",
    "files = [directory+'/std_output.log' for directory in dirs]\n",
    "\n",
    "hot_path_name = None\n",
    "\n",
    "# result maps each pair (exe, rmw) to lists of results corresponding to the runs\n",
    "results = defaultdict(lambda: [])\n",
    "\n",
    "hot_path_name_regex = re.compile(r'^ *hot path: *(.*)$')\n",
    "hot_path_latency_regex = re.compile(r'^ *hot path latency: *(.+)ms \\[min=(.+)ms, ' +\n",
    "                                    r'max=(.+)ms, average=(.+)ms, deviation=(.+)ms\\]$')\n",
    "hot_path_drops_regex = re.compile(r'^ *hot path drops: *(.+) \\[min=(.+), max=(.+), ' +\n",
    "                                  r'average=(.+), deviation=(.+)\\]$')\n",
    "behavior_planner_period_regex = re.compile(r'^ *behavior planner period: *(.+)ms \\[' +\n",
    "                                            r'min=(.+)ms, max=(.+)ms, average=(.+)ms, ' +\n",
    "                                            r'deviation=(.+)ms\\]$')\n",
    "\n",
    "rmw_regex = re.compile(r'^RMW Implementation: (rmw_.*)')\n",
    "filename_regex = re.compile(r'.*/([0-9]+)s/(rmw_.*)/(.*)/std_output.log')\n",
    "for count, file in enumerate(files):\n",
    "    match = filename_regex.match(file)\n",
    "    if not match:\n",
    "        raise ValueError(f'File {file} does not conform to the naming scheme')\n",
    "\n",
    "    extracted_duration, rmw, exe = match.groups()\n",
    "    if int(extracted_duration) != duration:\n",
    "        raise ValueError(f'File {file} does not match expected duration {duration}')\n",
    "    with open(file) as fp:\n",
    "        rmw_line, *data = fp.read().splitlines()\n",
    "\n",
    "    match = rmw_regex.match(rmw_line)\n",
    "    if match and rmw != match.groups()[0]:\n",
    "        raise ValueError((f'{file}: mismatch between filename-rmw (\"{rmw}\")' +\n",
    "                          f'and content-rmw(\"{match.groups()[0]}\")'))\n",
    "\n",
    "    if rmw not in file:\n",
    "        raise ValueError(f'File {file} contains data from RMW {rmw}, contradicting its name')\n",
    "\n",
    "    for line in data:\n",
    "        match = hot_path_name_regex.match(line)\n",
    "        if match:\n",
    "            name, = match.groups()\n",
    "            if hot_path_name is not None and hot_path_name != name:\n",
    "                raise ValueError('Two different hotpaths in a single summary: ' +\n",
    "                                  f'{name} {hot_path_name}')\n",
    "            hot_path_name = name\n",
    "            continue\n",
    "        match = hot_path_latency_regex.match(line)\n",
    "        if match:\n",
    "            results[exe].append(float(match.groups()[0]))\n",
    "            continue\n",
    "\n",
    "if hot_path_name is None:\n",
    "    raise RuntimeError('No hot_path defined in experiment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the style of the plot\n",
    "# sns.set_style({'axes.facecolor':'white', 'grid.color': '.8'})\n",
    "# sns.set_context(\"talk\")  # Adjust this for larger or smaller text\n",
    "# results[\"autoware_default_events\"].sort()\n",
    "# # results[\"autoware_default_fifo\"].sort()\n",
    "# results[\"autoware_default_rm\"].sort()\n",
    "# results[\"autoware_default_singlethreaded\"].sort()\n",
    "# results[\"autoware_default_staticsinglethreaded\"].sort()\n",
    "# print(results[\"autoware_default_events\"][-5:])\n",
    "# # print(results[\"autoware_default_fifo\"][-5:])\n",
    "# print(results[\"autoware_default_rm\"][-5:])\n",
    "# print(results[\"autoware_default_singlethreaded\"][-5:])\n",
    "# print(results[\"autoware_default_staticsinglethreaded\"][-5:])\n",
    "\n",
    "# Creating the violin plot with specific color scheme and settings\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "# ax = sns.boxplot(data=results, color=\"#2171b5\", whis=100, linewidth=1.5, linecolor=\"#10385a\",\n",
    "#     fliersize=5, showfliers=False)\n",
    "parts = plt.violinplot([results[\"autoware_default_singlethreaded\"],\n",
    "                     results[\"autoware_default_staticsinglethreaded\"],\n",
    "                     results[\"autoware_default_events\"],\n",
    "                     results[\"autoware_default_rm\"]],\n",
    "                     positions=[0,1,2,3], showextrema=True)\n",
    "# for pc in parts['bodies']:\n",
    "#     pc.set_edgecolor('#ff0000')\n",
    "ax = sns.violinplot(data=results, palette=[\"#2171b5\", \"#2171b5\", \"#2171b5\", \"#2171b5\"],\n",
    "                    linewidth=0, inner_kws={\"box_width\": 0, \"whis_width\": 0}, cut=0,\n",
    "                    order=[\"autoware_default_singlethreaded\", \"autoware_default_staticsinglethreaded\", \"autoware_default_events\", \"autoware_default_rm\"])\n",
    "# sns.boxplot(results, width=1, whis=100)\n",
    "\n",
    "# Customizing the look and feel of the plot to match the bar graph\n",
    "ax.set_ylabel(\"Latency (ms)\", fontsize=16, labelpad=10)  # Y-axis Label\n",
    "ax.set_title(\"Latency Summary 600s [FrontLidarDriver/RearLidarDriver -> ObjectCollision]\", fontsize=16, pad=20)  # Title\n",
    "\n",
    "# Setting y-axis limits and labels similar to the bar chart\n",
    "ax.set_ybound(0, 100)  # Y-axis Bounds\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(10))  # Major ticks every 10 units\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(2))   # Minor ticks every 2 units\n",
    "\n",
    "# Enable grid only for major ticks on the y-axis\n",
    "ax.grid(True, which='major', linestyle='-', linewidth=0.5)\n",
    "ax.grid(True, which='minor', linestyle='', linewidth=0)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_yticklabels([int(x) for x in ax.get_yticks()], size=12)  # Y-axis Ticks\n",
    "ax.set_xticklabels([\"Default\", \"Static\", \"Events (RO)\", \"RM (RO)\"], ha=\"center\", fontsize=16)\n",
    "\n",
    "# Remove top and right borders for a cleaner look\n",
    "sns.despine(fig=None, ax=None, top=True, right=True, left=False, bottom=False, offset=None, trim=False)\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"latency_violin.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTSIDE = 0\n",
    "ENQUEUE = 1\n",
    "LOCKED = 2\n",
    "INIT = 3\n",
    "LOOPING = 4\n",
    "POST = 5\n",
    "state = 0\n",
    "overheads = []\n",
    "loops = []\n",
    "overhead = 0\n",
    "\n",
    "with open(\"timers_manager_overhead.txt\", 'r') as fin:\n",
    "  for line in fin:\n",
    "    if state == OUTSIDE:\n",
    "      if \"release_entry\" in line:\n",
    "        overhead = 0\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        timestamp = now\n",
    "        state = ENQUEUE\n",
    "    elif state == ENQUEUE:\n",
    "      if \"lock_entry\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        overhead += now - timestamp\n",
    "        timestamp = now\n",
    "        state = LOCKED\n",
    "    elif state == LOCKED:\n",
    "      if \"lock_exit\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        # overhead += now - timestamp\n",
    "        timestamp = now\n",
    "        state = INIT\n",
    "    elif state == INIT:\n",
    "      if \"loop\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        overhead += now - timestamp\n",
    "        timestamp = now\n",
    "        state = LOOPING\n",
    "    elif state == LOOPING:\n",
    "      if \"loop\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        loops.append((now - timestamp)*1000000)\n",
    "        timestamp = now\n",
    "      elif \"unlock\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        loops.append((now - timestamp)*1000000)\n",
    "        timestamp = now\n",
    "        state = POST\n",
    "    elif state == POST:\n",
    "      if \"release_exit\" in line:\n",
    "        now = float(line.split(\":\")[0].split(' ')[-1])\n",
    "        overhead += now - timestamp\n",
    "        overheads.append(overhead*1000000)\n",
    "        state = OUTSIDE\n",
    "\n",
    "# Create a violin plot using seaborn\n",
    "sns.violinplot(data={\"k\": overheads, \"δ\": loops})\n",
    "print(\"Const overhead Max: \" + str(max(overheads)))\n",
    "print(\"Loop overhead Max: \" + str(max(loops)))\n",
    "print(\"Const overhead 99%: \" + str(np.percentile(overheads, 99)))\n",
    "print(\"Loop overhead 99%: \" + str(np.percentile(loops, 99)))\n",
    "\n",
    "# Add labels and title\n",
    "# plt.xlabel('Data')\n",
    "plt.ylabel('us')\n",
    "plt.title('Overhead of RO Mode')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = \"data/timers_only_05_23/\"\n",
    "\n",
    "samples = {}\n",
    "lidar_array = []\n",
    "imu_array = []\n",
    "camera_array = []\n",
    "temp_array = []\n",
    "df = pd.DataFrame(columns=[\"Executor\", \"Utilization\", \"Node\", \"Response Time\"])\n",
    "for directory in os.listdir(root_dir):\n",
    "  if \"response_time\" in directory:\n",
    "    utilization = directory.split(\".\")[-1]\n",
    "    executor = directory.replace(\"response_time.\", \"\").replace('.' + utilization, \"\")\n",
    "    for file in os.listdir(root_dir + directory):\n",
    "      temp_array = []\n",
    "      with open(root_dir + directory + \"/\" + file, 'r') as fin:\n",
    "        for line in fin:\n",
    "          temp_array.append(float(line.strip())/1000000.0)\n",
    "      if \"Lidar\" in file:\n",
    "        df_to_add = pd.DataFrame({\"Executor\": [executor]*len(temp_array),\n",
    "                              \"Utilization\": [utilization]*len(temp_array),\n",
    "                              \"Node\": [\"Lidar\"]*len(temp_array),\n",
    "                              \"Response Time\": temp_array})\n",
    "        df = pd.concat([df, df_to_add])\n",
    "      elif \"IMU\" in file:\n",
    "        df_to_add = pd.DataFrame({\"Executor\": [executor]*len(temp_array),\n",
    "                              \"Utilization\": [utilization]*len(temp_array),\n",
    "                              \"Node\": [\"IMU\"]*len(temp_array),\n",
    "                              \"Response Time\": temp_array})\n",
    "        df = pd.concat([df, df_to_add])\n",
    "      elif \"Camera\" in file:\n",
    "        df_to_add = pd.DataFrame({\"Executor\": [executor]*len(temp_array),\n",
    "                              \"Utilization\": [utilization]*len(temp_array),\n",
    "                              \"Node\": [\"Camera\"]*len(temp_array),\n",
    "                              \"Response Time\": temp_array})\n",
    "        df = pd.concat([df, df_to_add])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.violinplot(data=df[df[\"Node\"] == \"Camera\"], x=\"Executor\", y=\"Response Time\", hue=\"Utilization\",\n",
    "    palette=[\"#004d4c\", \"#008080\", \"#5ca3a3\"], linewidth=0.5, cut=0, hue_order=[\"60\", \"80\", \"90\"],\n",
    "    order=[\"default\", \"static\", \"events.re\", \"events.ro\", \"edf.re\", \"edf.ro\", \"rm.re\", \"rm.ro\"],\n",
    "    inner_kws={\"box_width\": 1, \"whis_width\": 0})\n",
    "ax.set_title(\"Response Time, Cameras\")\n",
    "ax.set_ylabel(\"Response Time (ms)\")\n",
    "# ax.set_ylim([0, 85])\n",
    "ax.set_xticklabels([\"Default\", \"Static\", \"Events (RE)\", \"Events (RO)\", \"EDF (RE)\", \"EDF (RO)\", \"RM (RE)\", \"RM (RO)\"], ha=\"center\", rotation=30)\n",
    "\n",
    "plt.savefig(\"response_times_cameras.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'default') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'default') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'default') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'static') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'static') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'static') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Camera') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.violinplot(data=df[df[\"Node\"] == \"Lidar\"], x=\"Executor\", y=\"Response Time\", hue=\"Utilization\",\n",
    "    palette=[\"#004d4c\", \"#008080\", \"#5ca3a3\"], linewidth=0.5, cut=0, hue_order=[\"60\", \"80\", \"90\"],\n",
    "    order=[\"default\", \"static\", \"events.re\", \"events.ro\", \"edf.re\", \"edf.ro\", \"rm.re\", \"rm.ro\"],\n",
    "    inner_kws={\"box_width\": 1, \"whis_width\": 0})\n",
    "ax.set_title(\"Response Time, LiDAR\")\n",
    "ax.set_ylabel(\"Response Time (ms)\")\n",
    "# ax.set_ylim([0, 200])\n",
    "ax.set_xticklabels([\"Default\", \"Static\", \"Events (RE)\", \"Events (RO)\", \"EDF (RE)\", \"EDF (RO)\", \"RM (RE)\", \"RM (RO)\"], ha=\"center\", rotation=30)\n",
    "\n",
    "plt.savefig(\"response_times_lidar.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'default') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'default') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'default') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'static') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'static') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'static') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'Lidar') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax = sns.violinplot(data=df[df[\"Node\"] == \"IMU\"], x=\"Executor\", y=\"Response Time\", hue=\"Utilization\",\n",
    "    palette=[\"#004d4c\", \"#008080\", \"#5ca3a3\"], linewidth=0.5, cut=0, hue_order=[\"60\", \"80\", \"90\"],\n",
    "    order=[\"default\", \"static\", \"events.re\", \"events.ro\", \"edf.re\", \"edf.ro\", \"rm.re\", \"rm.ro\"],\n",
    "    inner_kws={\"box_width\": 1, \"whis_width\": 0})\n",
    "ax.set_title(\"Response Time, IMU\")\n",
    "ax.set_ylabel(\"Response Time (ms)\")\n",
    "# ax.set_ylim([0, 40])\n",
    "ax.set_xticklabels([\"Default\", \"Static\", \"Events (RE)\", \"Events (RO)\", \"EDF (RE)\", \"EDF (RO)\", \"RM (RE)\", \"RM (RO)\"], ha=\"center\", rotation=30)\n",
    "ax.axhline(y=30, linewidth=1, color='r', linestyle='--')\n",
    "\n",
    "plt.savefig(\"response_times_imu.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'default') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'default') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'default') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'static') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'static') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'static') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'events.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'edf.ro') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.re') & (df['Utilization'] == '90')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '60')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '80')]['Response Time']))\n",
    "print(max(df[(df['Node'] == 'IMU') & (df['Executor'] == 'rm.ro') & (df['Utilization'] == '90')]['Response Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# start_time = \"2024-05-22T23:59:21.305\"\n",
    "# end_time = \"2024-05-22T23:59:21.350\"\n",
    "\n",
    "# df = callback_df[(callback_df['timestamp'] >= start_time) & (callback_df['timestamp'] <= end_time)].copy()\n",
    "# df[\"start\"] = df[\"timestamp\"]\n",
    "# df[\"end\"] = df[\"timestamp\"] + df[\"duration\"]\n",
    "# fig = px.timeline(df, x_start=\"start\", x_end=\"end\", y=\"Executor\", color=\"Node\")\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
