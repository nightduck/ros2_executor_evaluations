{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "ROS_DISTRO = 'rolling'\n",
    "sys.path.insert(0, f'/opt/ros/{ROS_DISTRO}/lib/python3.121/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tracetools_analysis.loading import load_file\n",
    "from tracetools_analysis.processor.ros2 import Ros2Handler\n",
    "from tracetools_analysis.utils.ros2 import Ros2DataModelUtil\n",
    "\n",
    "def load_dropped_jobs(filename):\n",
    "  with open(filename, 'r') as f:\n",
    "    dropped_jobs = {}\n",
    "    process_line = False\n",
    "    for line in f:\n",
    "      if line.startswith(\"Dropped jobs:\"):\n",
    "        process_line = True\n",
    "        continue\n",
    "      if process_line:\n",
    "        name, stats = line.strip().split(\":\")\n",
    "        dropped, total = [int(x) for x in stats.split(\"/\")]\n",
    "        dropped_jobs[name.strip()] = float(dropped) / float(total) if total > 0 else 0\n",
    "    return dropped_jobs\n",
    "\n",
    "def get_node_name(owner_info):\n",
    "  node_name = owner_info.split(\",\")[0].split(\":\")[1].strip()\n",
    "  return node_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trace directory or converted trace file\n",
    "directory_prefix = \"timers_only_hu_edf_fix/\"\n",
    "events_dict = {}\n",
    "events_dict[\"RM, (RO)\"] =     (load_file(directory_prefix + 'timers-only-rm-ro'),     load_dropped_jobs(directory_prefix + 'timers-only-rm-ro.log'))\n",
    "events_dict[\"RM, (RE)\"] =     (load_file(directory_prefix + 'timers-only-rm-re'),     load_dropped_jobs(directory_prefix + 'timers-only-rm-re.log'))\n",
    "events_dict[\"EDF, (RO)\"] =    (load_file(directory_prefix + 'timers-only-edf-ro'),    load_dropped_jobs(directory_prefix + 'timers-only-edf-ro.log'))\n",
    "events_dict[\"EDF, (RE)\"] =    (load_file(directory_prefix + 'timers-only-edf-re'),    load_dropped_jobs(directory_prefix + 'timers-only-edf-re.log'))\n",
    "events_dict[\"Events, (RO)\"] = (load_file(directory_prefix + 'timers-only-events-ro'), load_dropped_jobs(directory_prefix + 'timers-only-events-ro.log'))\n",
    "events_dict[\"Events, (RE)\"] = (load_file(directory_prefix + 'timers-only-events-re'), load_dropped_jobs(directory_prefix + 'timers-only-events-re.log'))\n",
    "events_dict[\"Default\"] =      (load_file(directory_prefix + 'timers-only-default'),   load_dropped_jobs(directory_prefix + 'timers-only-default.log'))\n",
    "\n",
    "dropped_df = pd.DataFrame({\"Executor\": [], \"Node\": [], \"Drop Rate\": []})\n",
    "wcet_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, events in events_dict.items():\n",
    "  dropped_jobs = events[1]\n",
    "  for node, drop_rate in dropped_jobs.items():\n",
    "    dropped_df = pd.concat([pd.DataFrame([[name, node, drop_rate]], columns=dropped_df.columns), dropped_df], ignore_index=True)\n",
    "\n",
    "  # Process\n",
    "  handler = Ros2Handler.process(events[0])\n",
    "\n",
    "  # Use data model utils to extract information\n",
    "  data_util = Ros2DataModelUtil(handler.data)\n",
    "  callback_symbols = data_util.get_callback_symbols()\n",
    "\n",
    "  # callback_symbols = ros2_util.get_callback_symbols()\n",
    "  for callback_object in callback_symbols.keys():\n",
    "    owner_info = data_util.get_callback_owner_info(callback_object)\n",
    "    if \"parameter_events\" in owner_info:\n",
    "      continue\n",
    "    owner_name = get_node_name(owner_info)\n",
    "    # callback_durations = data_util.get_callback_durations(callback_object)\n",
    "    callback_durations = data_util.get_callback_durations(callback_object)[[\"duration\"]].to_numpy(dtype=np.float64) / 1000000000.0\n",
    "    if owner_name not in wcet_dict:\n",
    "      wcet_dict[owner_name] = callback_durations.flatten()\n",
    "    else:\n",
    "      wcet_dict[owner_name] = np.concatenate((wcet_dict[owner_name], callback_durations.flatten())).flatten()\n",
    "\n",
    "    # print(time_per_thread)\n",
    "    # print(owner_info)\n",
    "    # print(callback_durations)\n",
    "\n",
    "total_drops_df = dropped_df[dropped_df[\"Node\"] == \"Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(total_drops_df, y=\"Drop Rate\", x=\"Executor\")\n",
    "ax.set_title(\"Drop Rate by Executor\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "plt.show()\n",
    "\n",
    "for k in wcet_dict.keys():\n",
    "  wcet_dict[k] = wcet_dict[k][wcet_dict[k] < 0.1]\n",
    "sns.violinplot(wcet_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timeline\n",
    "executor = \"EDF, (RO)\"\n",
    "\n",
    "events = events_dict[executor][0]\n",
    "\n",
    "# Process\n",
    "handler = Ros2Handler.process(events)\n",
    "\n",
    "# Use data model utils to extract information\n",
    "data_util = Ros2DataModelUtil(handler.data)\n",
    "callback_symbols = data_util.get_callback_symbols()\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# TODO: Amalgamate these into one pandas dataframe\n",
    "# callback_symbols = ros2_util.get_callback_symbols()\n",
    "for callback_object in callback_symbols.keys():\n",
    "  owner_info = data_util.get_callback_owner_info(callback_object)\n",
    "  if \"parameter_events\" in owner_info:\n",
    "    continue\n",
    "  owner_name = get_node_name(owner_info)\n",
    "  # callback_durations = data_util.get_callback_durations(callback_object)\n",
    "  callback_events = data_util.get_callback_durations(callback_object)\n",
    "  callback_events['owner'] = owner_name\n",
    "  dataframes.append(callback_events)\n",
    "  \n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.sort_values(by=['timestamp'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
